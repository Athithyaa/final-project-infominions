{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network Visualization - Create Models\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Current Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "os.chdir(current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0b. CIFAR class\n",
    "\n",
    "Reference: https://www.bonaccorso.eu/2016/08/06/cifar-10-image-classification-with-keras-convnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cifar10(object):\n",
    "    def __init__(self, data_folder, n_training_files=5, image_width=32, image_height=32, n_components=3,\n",
    "                 data_block_size=10000, training_set_size=50000, test_set_size=10000, n_classes=10):\n",
    " \n",
    "        self.data_folder = data_folder\n",
    "        self.n_training_files = n_training_files\n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        self.n_components = n_components\n",
    "        self.data_block_size = data_block_size\n",
    "        self.training_set_size = training_set_size\n",
    "        self.test_set_size = test_set_size\n",
    "        self.n_classes = n_classes\n",
    " \n",
    "        # Define training and test sets\n",
    "        self.training_set = np.ndarray(shape=(self.training_set_size, self.n_components, self.image_width, self.image_height)).astype(np.float32)\n",
    "        self.training_set_labels = np.ndarray(shape=(self.training_set_size, self.n_classes)).astype(np.float32)\n",
    " \n",
    "        self.test_set = np.ndarray(shape=(self.test_set_size, self.n_components, self.image_width, self.image_height)).astype(np.float32)\n",
    "        self.test_set_labels = np.ndarray(shape=(self.test_set_size, self.n_classes)).astype(np.float32)\n",
    " \n",
    "        # Load data\n",
    "        print('Loading training data')\n",
    " \n",
    "        # Read training data\n",
    "        for i in range(n_training_files):\n",
    "            with open(self.data_folder + 'data_batch_' + str(i + 1), 'rb') as training_file:\n",
    "                training_dict = cPickle.load(training_file, encoding='latin1')\n",
    " \n",
    "                self.training_set[(self.data_block_size * i):(self.data_block_size * (i + 1)), :, :, :] = training_dict['data']. \\\n",
    "                    reshape((self.data_block_size, self.n_components, self.image_width, self.image_height)).astype(np.float32)\n",
    " \n",
    "                for idx, label in enumerate(training_dict['labels']):\n",
    "                    self.training_set_labels[(self.data_block_size * i) + idx, :] = self.to_class(label)\n",
    " \n",
    "        # Read test data\n",
    "        print('Loading test data')\n",
    " \n",
    "        with open(self.data_folder + 'test_batch', 'rb') as test_file:\n",
    "            test_dict = cPickle.load(test_file, encoding='latin1')\n",
    " \n",
    "            self.test_set[0:self.data_block_size, :, :, :] = test_dict['data']. \\\n",
    "                reshape((self.data_block_size, self.n_components, self.image_width, self.image_height)).astype(np.float32)\n",
    " \n",
    "            for idx, label in enumerate(test_dict['labels']):\n",
    "                self.test_set_labels[idx, :] = self.to_class(label)\n",
    " \n",
    "        # Read label data\n",
    "        with open(data_folder + 'batches.meta', 'rb') as label_file:\n",
    "            self.label_dict = cPickle.load(label_file, encoding='latin1')\n",
    "            self.label_names = self.label_dict['label_names']\n",
    " \n",
    "        # Normalize training and test data\n",
    "        self.X_train, self.Y_train = (self.training_set / 255), self.training_set_labels\n",
    "        self.X_test, self.Y_test = (self.test_set / 255), self.test_set_labels\n",
    " \n",
    "    def to_class(self, label_idx):\n",
    "        class_data = np.zeros(shape=self.n_classes).astype(np.float32)\n",
    "        class_data[label_idx] = 1.0\n",
    "        return class_data\n",
    " \n",
    "    def to_label(self, class_vector):\n",
    "        return self.label_names[np.argmax(class_vector)]\n",
    " \n",
    "    def to_RGB(self, data):\n",
    "        img = np.ndarray(shape=(self.image_width, self.image_height, self.n_components)).astype(np.uint8)\n",
    " \n",
    "        for i in range(self.n_components):\n",
    "            img[:, :, i] = data[i, :, :]\n",
    " \n",
    "        return img\n",
    " \n",
    "    def show_image(self, i, data_set='training'):\n",
    "        if data_set == 'test':\n",
    "            a_data_set = self.test_set\n",
    "            a_data_set_labels = self.test_set_labels\n",
    "        else:\n",
    "            a_data_set = self.training_set\n",
    "            a_data_set_labels = self.training_set_labels\n",
    " \n",
    "        plt.imshow(self.to_RGB(a_data_set[i]))\n",
    "        plt.show()\n",
    "        return a_data_set_labels[i]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-10-f8e5989a1124>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-f8e5989a1124>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    model = Sequential()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create Keras model\n",
    "    model = Sequential()\n",
    " \n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='valid', activation='relu',\n",
    "                            input_shape=(cifar10.n_components, cifar10.image_height, cifar10.image_width)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='valid', activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    " \n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    " \n",
    "    # Try to remove some convolutional layer\n",
    "    model.add(Convolution2D(256, 3, 3, border_mode='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    " \n",
    "    model.add(Convolution2D(512, 3, 3, border_mode='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    " \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(cifar10.n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    " \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " \n",
    "    print('Fitting model')\n",
    "    model.fit(cifar10.X_train, cifar10.Y_train, batch_size=32, nb_epoch=15, validation_data=(cifar10.X_test, cifar10.Y_test))\n",
    " \n",
    "    print('Evalutating model')\n",
    "    score = model.evaluate(cifar10.X_test, cifar10.Y_test, verbose=0)\n",
    " \n",
    "    print('Score: %1.3f' % score[0])\n",
    "    print('Accuracy: %1.3f' % score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup Training / Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data\n",
      "Loading test data\n"
     ]
    }
   ],
   "source": [
    "cifar10 = Cifar10(data_folder='datasets/cifar-10-batches-py/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_components = cifar10.n_components\n",
    "cifar_img_height = cifar10.image_height\n",
    "cifar_img_width = cifar10.image_width\n",
    "\n",
    "input_shape = (cifar_img_height, cifar_img_width, cifar_components)\n",
    "num_classes = cifar10.n_classes\n",
    "\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = cifar10.X_train\n",
    "Y_train = cifar10.Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = cifar10.X_test\n",
    "Y_test = cifar10.Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y data (labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Construct Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Setup Create New Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_new_model():\n",
    "    \n",
    "    # Instantiate sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Conv layer 1\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='valid', input_shape=input_shape, data_format = \"channels_last\"))\n",
    "    \n",
    "    # Pooling layer 1\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format = \"channels_last\"))\n",
    "    \n",
    "    # Activation 1\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Convlayer 2\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='valid', data_format = \"channels_last\"))\n",
    "    \n",
    "    # Pooling layer 2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='valid', data_format = \"channels_last\"))\n",
    "    \n",
    "    # Zero padding 2d\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    \n",
    "    # Convlayer 3\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding='valid', data_format = \"channels_last\"))\n",
    "    \n",
    "    # Activation 3\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Pooling layer 3\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format = \"channels_last\"))\n",
    "    \n",
    "    # Zero padding 2d\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    \n",
    "    # Convlayer 4\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), padding='valid', data_format = \"channels_last\"))\n",
    "    \n",
    "    # Activation 4\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Pooling layer 4\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format = \"channels_last\"))\n",
    "    \n",
    "    # Zero padding 2d\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    \n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "    \n",
    "    # Print summary\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     # Convlayer 5\n",
    "#     model.add(Conv2D(filters=512, kernel_size=(3, 3), padding='valid', data_format = \"channels_last\"))\n",
    "    \n",
    "#     # Activation 5\n",
    "#     model.add(Activation('relu'))\n",
    "    \n",
    "#     # Pooling layer 5\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2), data_format = \"channels_last\"))\n",
    "    \n",
    "#     # Zero padding 2d\n",
    "#     model.add(ZeroPadding2D((1, 1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Generate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPaddi (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPaddi (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 684,746.0\n",
      "Trainable params: 684,746.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(input_shape)\n",
    "model = create_new_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Setup Train Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MODEL_ARCH_FILEPATH = 'models/model.json'\n",
    "WEIGHTS_FILEPATH=\"models/weights/weights-improvement-epoch_{epoch:02d}-acc_{val_acc:.2f}.hdf5\"\n",
    "\n",
    "batch_size = 32\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model saving callback\n",
    "checkpointer = ModelCheckpoint(filepath=WEIGHTS_FILEPATH, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: expected conv2d_33_input to have shape (None, 32, 32, 3) but got array with shape (50000, 3, 32, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-2f0b051c3427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1,\n\u001b[1;32m      3\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           validation_data=(X_test, Y_test))\n\u001b[0m",
      "\u001b[0;32m/Users/mliuzzolino/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/mliuzzolino/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1403\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1406\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mliuzzolino/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                                     exception_prefix='model input')\n\u001b[0m\u001b[1;32m   1296\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1297\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mliuzzolino/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    131\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: expected conv2d_33_input to have shape (None, 32, 32, 3) but got array with shape (50000, 3, 32, 32)"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1,\n",
    "          callbacks=[checkpointer, early_stopping], \n",
    "          validation_data=(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(MODEL_ARCH_FILEPATH, 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
